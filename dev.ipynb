{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperationError",
     "evalue": "conversion from `str` to `datetime[μs, UTC]` failed in column 'start_date_local' for 197 out of 197 values: [\"2024-08-19 19:51:10\", \"2024-08-17 07:49:51\", … \"2023-01-14 10:03:25\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperationError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m polars_df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mfrom_pandas(df)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#convert dates to datetime\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m polars_df \u001b[38;5;241m=\u001b[39m \u001b[43mpolars_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatetime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart_date_local\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatetime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m schema \u001b[38;5;241m=\u001b[39m polars_df\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#auth openai\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/polars/dataframe/frame.py:8890\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_columns\u001b[39m(\n\u001b[1;32m   8745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8746\u001b[0m     \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   8747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   8748\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8749\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8750\u001b[0m \u001b[38;5;124;03m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   8751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8888\u001b[0m \u001b[38;5;124;03m    └─────┴──────┴─────────────┘\u001b[39;00m\n\u001b[1;32m   8889\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/polars/lazyframe/frame.py:2027\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mInvalidOperationError\u001b[0m: conversion from `str` to `datetime[μs, UTC]` failed in column 'start_date_local' for 197 out of 197 values: [\"2024-08-19 19:51:10\", \"2024-08-17 07:49:51\", … \"2023-01-14 10:03:25\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"./test_activities.csv\")\n",
    "\n",
    "# Assuming you have a pandas DataFrame named df\n",
    "polars_df = pl.from_pandas(df)\n",
    "\n",
    "#convert dates to datetime\n",
    "polars_df = polars_df.with_columns(\n",
    "    [\n",
    "        pl.col(\"start_date\").str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S%z\"),\n",
    "        pl.col(\"start_date_local\").str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S%z\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "schema = polars_df.schema\n",
    "\n",
    "#auth openai\n",
    "openai = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(query):\n",
    "    return polars_df.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tool\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_data\",\n",
    "            \"description\": \"Query Strava Data using SQL Queries. Call this whenever you need to execute an SQL query on Strava data.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The SQL query to execute\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"You are an AI assistant specialized in analyzing Strava Activity data\",\n",
      "  \"context\": {\n",
      "    \"about_task\": \"You answer questions from the athlete about their Strava Training data and provide useful insights and suggestions.\",\n",
      "    \"current_date\": \"2024-08-22 10:39:10.271397\"\n",
      "  },\n",
      "  \"task\": {\n",
      "    \"instructions\": [\n",
      "      \"Analyse the question or response from the user\",\n",
      "      \"If necessary use the tools provided to query the data\",\n",
      "      \"Analyse the data you have requested\",\n",
      "      \"Craft a response for the user to provide valuable insights based on the data\"\n",
      "    ],\n",
      "    \"hallucination_prevention\": \"If the question cannot be answered based on the provided context, respond with \\\"I don't know\\\".\"\n",
      "  },\n",
      "  \"additional_guidelines\": {\n",
      "    \"guideline\": [\n",
      "      \"Use chain-of-thought reasoning for complex synthesis tasks.\",\n",
      "      \"Avoid being overly verbose and take an informal tone in your answer to the question.\"\n",
      "    ]\n",
      "  },\n",
      "  \"Polar DataFrame\": {\n",
      "    \"description\": \"Strava Data is kept in a singular Polar DataFrame with columns outlined in the following schema. When calling the table use \\\"self\\\" to refer to the Polar DataFrame.\",\n",
      "    \"schema\": \"Schema([('id', Int64), ('achievement_count', Int64), ('athlete_id', Float64), ('athlete_count', Int64), ('average_speed', Float64), ('average_watts', Float64), ('comment_count', Int64), ('commute', Boolean), ('device_watts', Boolean), ('distance', Float64), ('elapsed_time', Int64), ('elev_high', Float64), ('elev_low', Float64), ('end_latlng_lat', Float64), ('end_latlng_lng', Float64), ('external_id', String), ('flagged', Boolean), ('gear_id', String), ('has_kudoed', Boolean), ('hide_from_home', Float64), ('kilojoules', Float64), ('kudos_count', Int64), ('manual', Boolean), ('map_id', Float64), ('map_summary_polyline', Float64), ('max_speed', Float64), ('max_watts', Float64), ('moving_time', Int64), ('name', String), ('photo_count', Int64), ('private', Boolean), ('sport_type', String), ('start_date', Datetime(time_unit='us', time_zone='UTC')), ('start_date_local', Datetime(time_unit='us', time_zone='UTC')), ('start_latlng_lat', Float64), ('start_latlng_lng', Float64), ('timezone', String), ('total_elevation_gain', Float64), ('total_photo_count', Int64), ('trainer', Boolean), ('type', String), ('upload_id', Int64), ('upload_id_str', Int64), ('weighted_average_watts', Float64), ('workout_type', Float64), ('best_efforts', Float64), ('calories', Float64), ('description', Float64), ('device_name', Float64), ('embed_token', Float64), ('gear', Float64), ('laps', Float64), ('photos', Float64), ('segment_efforts', Float64), ('splits_metric', Float64), ('splits_standard', Float64), ('guid', Float64), ('utc_offset', Float64), ('location_city', Float64), ('location_state', Float64), ('location_country', String), ('start_latitude', Float64), ('start_longitude', Float64), ('pr_count', Int64), ('suffer_score', Float64), ('has_heartrate', Boolean), ('average_heartrate', Float64), ('max_heartrate', Float64), ('average_cadence', Float64), ('average_temp', Float64), ('instagram_primary_photo', Float64), ('partner_logo_url', Float64), ('partner_brand_tag', Float64), ('from_accepted_tag', Boolean), ('segment_leaderboard_opt_out', Float64), ('perceived_exertion', Float64), ('athlete', String), ('end_latlng', String), ('map', String), ('start_latlng', String)])\"\n",
      "  },\n",
      "  \"examples\": {\n",
      "    \"input\": \"What was the longest distance that I ran this year? (2024)\",\n",
      "    \"output\": \"The longest distance that you ran in 2024 was 20km.\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = open(\"./system_prompt.txt\").read().replace(\"***schema***\", str(schema))\n",
    "system_prompt = system_prompt.replace(\"***current_date***\", str(datetime.now()))\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperationError",
     "evalue": "conversion from `str` to `date` failed in column 'literal' for 1 out of 1 values: [\"now\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperationError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m json_args \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments\n\u001b[1;32m     18\u001b[0m query \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_args)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mquery_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dicts())\n\u001b[1;32m     21\u001b[0m function_call_result_message \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(result),\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_id\n\u001b[1;32m     25\u001b[0m }\n\u001b[1;32m     27\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mquery_data\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_data\u001b[39m(query):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpolars_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/polars/dataframe/frame.py:5032\u001b[0m, in \u001b[0;36mDataFrame.sql\u001b[0;34m(self, query, table_name)\u001b[0m\n\u001b[1;32m   5030\u001b[0m name \u001b[38;5;241m=\u001b[39m table_name \u001b[38;5;28;01mif\u001b[39;00m table_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5031\u001b[0m ctx\u001b[38;5;241m.\u001b[39mregister(name\u001b[38;5;241m=\u001b[39mname, frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 5032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/polars/sql/context.py:440\u001b[0m, in \u001b[0;36mSQLContext.execute\u001b[0;34m(self, query, eager)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03mParse the given SQL query and execute it against the registered frame data.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m└────────┴─────────────┴─────────┘\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m res \u001b[38;5;241m=\u001b[39m wrap_ldf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctxt\u001b[38;5;241m.\u001b[39mexecute(query))\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m (eager \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eager_execution) \u001b[38;5;28;01melse\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/polars/lazyframe/frame.py:2027\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mInvalidOperationError\u001b[0m: conversion from `str` to `date` failed in column 'literal' for 1 out of 1 values: [\"now\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "while True:\n",
    "    message = input()\n",
    "    if message == \"exit\":\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        tool_id = response.choices[0].message.tool_calls[0].id\n",
    "        json_args = response.choices[0].message.tool_calls[0].function.arguments\n",
    "        query = json.loads(json_args)[\"query\"]\n",
    "        result = str(query_data(query).to_dicts())\n",
    "       \n",
    "        function_call_result_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(result),\n",
    "            \"tool_call_id\": tool_id\n",
    "        }\n",
    "        \n",
    "        messages.append(response.choices[0].message)\n",
    "        messages.append(function_call_result_message)\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        print(response.choices[0].message.content)\n",
    "        messages.append({\"role\":\"system\", \"content\":response.choices[0].message.content})\n",
    "    else:\n",
    "        print(response.choices[0].message.content)\n",
    "        messages.append({\"role\": \"system\", \"content\": response.choices[0].message.content})\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
